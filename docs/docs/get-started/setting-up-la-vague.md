
# Installation & set up

In this section, we're going to walk you through how you can install and set up everything you need to run LaVague locally.

> If you just want to test out LaVague without having to install anything locally, you can run our [Quick Tour notebook with Google Colab](https://colab.research.google.com/github/lavague-ai/lavague/blob/main/docs/docs/get-started/quick-tour.ipynb).


To start using LaVague, we need to install a webdriver and store it in our home directory, so that LaVague can interact with the browser in our environment. We will then also need to install the LaVague package.

We provide two key installation options:

- Setting up LaVague in your environment [with our installation script](#local-setup)
- Setting up LaVague with [our pre-configured dev container](#dev-container-setup-docker-integration-ðŸ‹)

### Local setup

To set-up LaVague in your local environment, you can run our `setup.sh` script:

`sudo bash setup.sh`

This will perform all necessary steps to set-up LaVague.

> Feel free to inspect the script before running it.

### Dev container setup (Docker integration ðŸ‹)

âš ï¸ Pre-requisites:

- ðŸ‹ Docker: Ensure Docker is installed and running on your machine. Docker is used to create and manage your development container
- Visual Studio Code
- Visual Studio Code's Remote - Containers Extension: You can download this extension by searching for it within the Extensions view

To open the project in our dev container you need to:

1. Open VSCode at the root of the LaVague repo.
2. Click on the blue "><" icon in the bottom left corner, then select "Reopen in Container" in the drop-down menu that then appears.

VS Code will then build the container based on the Dockerfile and devcontainer.json files in the .devcontainer folder. This process might take a few minutes the first time you run it.

> Note, if you want to view your Gradio in-browser on your host machine, make sure to use the `public URL` generated by `lavague-launch`!

### ðŸš¨ Disclaimer

This project executes LLM-generated code using `exec`. This is not considered a safe practice. We therefore recommend taking extra care when using LaVague (such as running LaVague in a sandboxed environment)!

## Conclusions

You are now ready to use LaVague with the integration of your choice. To see how to do this with our CLI, see our [quick tour](./quick-tour.ipynb) or [integration pages](../integrations/hugging-face-api.ipynb).