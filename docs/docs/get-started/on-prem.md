# LaVague On-Premise

While LaVague Agents are provided by default via a public API, we can also deploy LaVague Agents on-premise as a Docker image for entreprise users.

If you would like to deploy LaVague on-premise or find out more, please [get in touch](https://www.lavague.ai/contact).

![LaVague on prem Workflow light](https://raw.githubusercontent.com/lavague-ai/LaVague/drafting-some-docs/docs/assets/architecture-on-prem.png#only-light)
![Trajectory on prem dark](https://raw.githubusercontent.com/lavague-ai/LaVague/drafting-some-docs/docs/assets/architecture-on-prem-dark.png#only-dark)

## Architecture

LaVague on-premise is made up of a:

- LaVague Docker Application - contains the core logic to leverage LLMs to generate multi-action trajectories to generate and perform tasks on the web
- Agent Studio - a locally hosted web interface to visualize and replay the trajectories generated by agents
- A Python SDK including methods to:
    - Facilitate calls to the Docker application
    - Exporters which convert generated actions into the format needed for specific use cases, such as PyTest scripts for web testing

## Definitions

Let's first define some key elements in our LaVague Agent architecture:

- `Objective`: The objective is the task the user wants the Web Agent to perform. For example: `"Log into my account and change my username to The WaveHunter."`
- `Action`: A single step needed to move towards achieving the objective, such as `click on the 'username' field`. For security reasons amongst others, we provide a pre-defined list of actions our agents can perform on web elements, such as clicking, entering a text value, etc.
- `Trajectory:` Once the agent has completed its run, it returns a trajectory object to the user which contains information about the run and the list of actions that were executed to reach the final objective. This list of actions could be converted to code and replayed in the future without needing an agent.
- `Driver`: The webdriver is leveraged for the execution of the action code and can also provide information to the Agent such as screenshots and HTML code of the reflecting the web page's latest state. For on-premise deployment, an on-premise web-driver will be used.

!!! info "More info"
    For a more detailed breakdown of Actions and the Trajectory items. See our [Learn section]().

## On-prem Workflow

Let's take a look at the basic LaVague workflow.

1. We use the `Python client SDK` to send a text `objective` and `URL` to the LaVague Docker image deployed on premise. We can also optionally send a `user_data` dictionary with key-value pairs of additional information to be taken into account by the agent.

2. This Docker application will leverage AI Web Agents to generate and perform the series of actions needed to achieve this objective. Planning and the generation of actions can be performed by remote or locally deployed LLMs. A local web driver is used to execute each action.

3. The agent will return a `Trajectory` JSON object, as outputting a URL for the `Agent Studio` web interface where users can view the Web Agent's actions live or a posteriori. 

4. The user can then optionally use this `Trajectory` object with additional integrations, such as converting the `trajectory` into code or a PyTest script that can be used for web testing.