{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: lavague 1.1.19\n",
            "Uninstalling lavague-1.1.19:\n",
            "  Successfully uninstalled lavague-1.1.19\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y lavague"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tngfNgZN9nw",
        "outputId": "b3be45e0-e7f6-4fa0-c109-0065063fa24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///home/mithril/LaVague1/lavague-core\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (6.0.2)\n",
            "Requirement already satisfied: ipython<8.0.0,>=7.34.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (7.34.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (4.23.0)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.20 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (0.1.20)\n",
            "Requirement already satisfied: llama-index==0.10.56 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (0.10.56)\n",
            "Requirement already satisfied: llama-index-retrievers-bm25<0.2.0,>=0.1.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (0.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=5.1.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (5.2.2)\n",
            "Requirement already satisfied: lxml-html-clean<0.2.0,>=0.1.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (0.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.8 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (1.0.8)\n",
            "Requirement already satisfied: seaborn<0.14.0,>=0.13.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (0.13.2)\n",
            "Requirement already satisfied: tenacity<8.4.0,>=8.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (8.3.0)\n",
            "Requirement already satisfied: trafilatura<2.0.0,>=1.9.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from lavague-core==0.2.34) (1.12.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.2.9)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.13)\n",
            "Requirement already satisfied: llama-index-core==0.10.56 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.10.56)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.11)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.2.7)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.26)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.9)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.6)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.32)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index==0.10.56->lavague-core==0.2.34) (0.1.6)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (3.10.1)\n",
            "Requirement already satisfied: dataclasses-json in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.40.1)\n",
            "Requirement already satisfied: pandas in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (10.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (66.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.19.1)\n",
            "Requirement already satisfied: decorator in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (5.14.3)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (3.0.47)\n",
            "Requirement already satisfied: pygments in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (2.18.0)\n",
            "Requirement already satisfied: backcall in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core==0.2.34) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core==0.2.34) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core==0.2.34) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->lavague-core==0.2.34) (0.20.0)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (0.1.98)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (2.8.2)\n",
            "Requirement already satisfied: rank-bm25<0.3.0,>=0.2.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-retrievers-bm25<0.2.0,>=0.1.3->lavague-core==0.2.34) (0.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from seaborn<0.14.0,>=0.13.2->lavague-core==0.2.34) (3.9.1.post1)\n",
            "Requirement already satisfied: certifi in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (2024.7.4)\n",
            "Requirement already satisfied: courlan>=1.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (1.3.0)\n",
            "Requirement already satisfied: htmldate>=1.8.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (1.8.1)\n",
            "Requirement already satisfied: justext>=3.0.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (2.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.9.4)\n",
            "Requirement already satisfied: babel>=2.15.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from courlan>=1.2.0->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (2.15.0)\n",
            "Requirement already satisfied: tld>=0.13 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from courlan>=1.2.0->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (0.13)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from dataclasses-json->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (3.21.3)\n",
            "Requirement already satisfied: dateparser>=1.1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (2.9.0.post0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from jedi>=0.16->ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.8.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (3.10.6)\n",
            "Requirement already satisfied: llama-cloud>=0.0.11 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.56->lavague-core==0.2.34) (0.0.13)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core==0.2.34) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core==0.2.34) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core==0.2.34) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.4.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.56->lavague-core==0.2.34) (0.4.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core==0.2.34) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core==0.2.34) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core==0.2.34) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core==0.2.34) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn<0.14.0,>=0.13.2->lavague-core==0.2.34) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pandas->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pandas->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (2024.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pexpect>4.3->ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.34.0->lavague-core==0.2.34) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (2.20.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (3.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.56->lavague-core==0.2.34) (2.5)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (2024.7.24)\n",
            "Requirement already satisfied: tzlocal in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (5.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core==0.2.34) (3.0.0)\n",
            "Requirement already satisfied: anyio in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (0.14.0)\n",
            "Requirement already satisfied: click in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.4.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (0.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from python-dateutil>=2.8.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core==0.2.34) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.56->llama-index==0.10.56->lavague-core==0.2.34) (1.0.0)\n",
            "Building wheels for collected packages: lavague-core\n",
            "  Building editable for lavague-core (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for lavague-core: filename=lavague_core-0.2.34-py3-none-any.whl size=5715 sha256=b32d6ecc2a9f5d1194b1c0d56a9d5a9ec240f888eaa814b4ca621e2921f0f322\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7znad98l/wheels/eb/a2/6e/f50db1f68d45585e8f4e5299f6b9f0196d8d21bc59cca86a26\n",
            "Successfully built lavague-core\n",
            "Installing collected packages: lavague-core\n",
            "  Attempting uninstall: lavague-core\n",
            "    Found existing installation: lavague-core 0.2.34\n",
            "    Uninstalling lavague-core-0.2.34:\n",
            "      Successfully uninstalled lavague-core-0.2.34\n",
            "Successfully installed lavague-core-0.2.34\n"
          ]
        }
      ],
      "source": [
        "!pip install -e ../../lavague-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VyVbIOGgOR4N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"LAVAGUE_TELEMETRY\"] = \"NONE\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-gemini in /home/mithril/LaVague/laura/lib/python3.11/site-packages (0.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-llms-gemini) (0.5.4)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-llms-gemini) (0.10.56)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-llms-gemini) (10.4.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.140.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.33.0)\n",
            "Requirement already satisfied: protobuf in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.25.4)\n",
            "Requirement already satisfied: pydantic in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.10.1)\n",
            "Requirement already satisfied: dataclasses-json in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.40.1)\n",
            "Requirement already satisfied: pandas in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.9.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.9)\n",
            "Requirement already satisfied: click in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.7.24)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.3.1)\n",
            "Requirement already satisfied: certifi in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.0.5)\n",
            "Requirement already satisfied: idna in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.65.4)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (3.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (23.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/mithril/LaVague/laura/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fallback test 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response is Park Central New York \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from lavague.drivers.selenium import SeleniumDriver\n",
        "from lavague.core import PythonEngine\n",
        "\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from lavague.drivers.selenium import SeleniumDriver\n",
        "url = \"https://www.booking.com/searchresults.html?ss=New+York&ssne=New+York&ssne_untouched=New+York&label=gen173nr-1FCAEoggI46AdIM1gEaKcCiAEBmAExuAEZyAEP2AEB6AEB-AECiAIBqAIDuALD8PG1BsACAdICJDEzNDNiMDMzLTYzZWUtNGMyZS1hYjIxLTIwNGJmZWY5NThlMNgCBeACAQ&aid=304142&lang=en-us&sb=1&src_elem=sb&src=index&dest_id=20088325&dest_type=city&checkin=2024-08-14&checkout=2024-08-16&group_adults=2&no_rooms=1&group_children=0\"\n",
        "\n",
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", temperature=0.0)\n",
        "\n",
        "engine = PythonEngine(ocr_llm=llm, llm=llm, embedding=embedding, driver=selenium_driver, batch_size=5)\n",
        "ret = engine.execute_instruction(f\"Return the the name of a hotel with Sustainability certification\").output\n",
        "print(f\"response is {ret}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test that it won't use fallback when not necessary (we can tell by speed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS David Beckham was born on May 2, 1975.\n"
          ]
        }
      ],
      "source": [
        "instruction = \"How old is David Beckham?\"\n",
        "url = \"https://en.wikipedia.org/wiki/David_Beckham\"\n",
        "\n",
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=2000, temperature=0.0)\n",
        "\n",
        "v1 = PythonEngine(ocr_llm=llm, llm=llm, embedding=embedding, driver=selenium_driver)\n",
        "ret1 = v1.execute_instruction(instruction).output\n",
        "print(f\"ANSWER IS {ret1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fallback test 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS The first apartment in the results is 30 m². \n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the size in m2 of the first apartment in the results?\"\n",
        "url = \"https://www.lodgis.com/en/paris,long-term-rentals/rentals-furnished-paris_1.cat.html\"\n",
        "\n",
        "instruction = \"What is the name of the first hotel in the search results?\"\n",
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=2000, temperature=0.0)\n",
        "\n",
        "BATCH_SIZE=1\n",
        "method1 = PythonEngine(ocr_llm=llm, llm=llm, embedding=embedding, driver=selenium_driver, batch_size=BATCH_SIZE)\n",
        "ret1 = method1.execute_instruction(query).output\n",
        "print(f\"ANSWER IS {ret1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS Here are three hotels in Paris with a rating of over 8:\n",
            "\n",
            "* **The People - Paris Belleville:** 8.8 rating\n",
            "* **The People Paris Marais:** 8.6 rating\n",
            "* **Eklo Paris Porte de Versailles:** 9.1 rating \n",
            "\n"
          ]
        }
      ],
      "source": [
        "url=\"https://www.hostelworld.com/pwa/wds/s?q=Paris,%20Ile-de-France,%20France&country=Ile-de-France,%20France&city=Paris&type=city&id=14&from=2024-08-15&to=2024-08-18&guests=1&page=1\"\n",
        "query=\"List 3 hotels with a rating of over 8\"\n",
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=2000, temperature=0.0)\n",
        "\n",
        "method1 = PythonEngine(llm=llm, embedding=embedding, driver=selenium_driver)\n",
        "ret1 = method1.execute_instruction(query).output\n",
        "print(f\"ANSWER IS {ret1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS Alston Taggert\n"
          ]
        }
      ],
      "source": [
        "url = \"https://www.phillyreps.com/about\"\n",
        "query = \"Return the name of the graphic designer\"\n",
        "\n",
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=2000, temperature=0.0)\n",
        "\n",
        "v2 = PythonEngine(llm=llm, embedding=embedding, driver=selenium_driver)\n",
        "ret2 = v2.execute_instruction(query).output\n",
        "print(f\"ANSWER IS {ret2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"https://www.lavague.ai/\"\n",
        "query = \"What is said in the tweet by Thomas Wolf?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS Thomas Wolf tweeted that something is \"fully open-source and really cool\" and encourages people to check it out. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=2000, temperature=0.0)\n",
        "\n",
        "v2 = PythonEngine(llm=llm, embedding=embedding, driver=selenium_driver)\n",
        "ret2 = v2.execute_instruction(query).output\n",
        "print(f\"ANSWER IS {ret2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"https://wordpress.com/theme/negai?ref=logged-out-homepage-lp\"\n",
        "\n",
        "query = \"What is the title of the post posted on 5/24/2023 with the label Positivity\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS The title of the post posted on 5/24/2023 with the label Positivity is \"Harmony in Dissonance: The Melody of Enduring Relationships.\" \n",
            "\n"
          ]
        }
      ],
      "source": [
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=3000, temperature=0.0)\n",
        "\n",
        "v2 = PythonEngine(llm=llm, embedding=embedding, driver=selenium_driver, batch_size=3)\n",
        "ret2 = v2.execute_instruction(query).output\n",
        "print(f\"ANSWER IS {ret2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"https://www.sonjavanduelmen.com/\"\n",
        "query = \"What is the telephone number provided in the contact section?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER IS The telephone number provided in the contact section is +49 (0)172 158 2031. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "selenium_driver = SeleniumDriver(headless=False, url=url)\n",
        "input()\n",
        "\n",
        "embedding =  OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "llm = Gemini(model_name=\"models/gemini-1.5-flash-latest\", max_tokens=2000, temperature=0.0)\n",
        "\n",
        "v2 = PythonEngine(llm=llm, embedding=embedding, driver=selenium_driver)\n",
        "ret2 = v2.execute_instruction(query).output\n",
        "print(f\"ANSWER IS {ret2}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Laura (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
